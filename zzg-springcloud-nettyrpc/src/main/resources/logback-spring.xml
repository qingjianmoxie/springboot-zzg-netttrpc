<?xml version="1.0" encoding="UTF-8"?>

<!-- @desc:  日志定义模版 @author: zhouzhigang @date: 2018-04-27 -->

<configuration scan="true" scanPeriod="60 seconds" debug="false">

	<!-- 属性设置 -->
	<property name="cmpName" value="zzg-springcloud" />
	<property name="appName" value="zzg-springcloud-nettyrpc" />

	<!-- 应用名称 -->
	<contextName>${appName}</contextName>

	<!-- 控制台输出日志 appender类型：ConsoleAppender、FileAppender、RollingFileAppender -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<!-- encoder 默认配置为PatternLayoutEncoder example: 15:47:33 [main] INFO com.xx.xxx.logback.TestLog 
			- === info -->
		<encoder>
			<pattern>${cmpName}#-#${appName}#-#%d{yyyy-MM-dd HH:mm:ss.SSS}#-#[%thread]#-#%-5level#-#%logger{35}#-#%msg%n</pattern>
		</encoder>
	</appender>

	<!-- RollingFileAppender 自动切割文件 -->
	<appender name="FILE"
		class="ch.qos.logback.core.rolling.RollingFileAppender">

		<!-- filer只收集info级别， EvaluatorFilter暂时不用，另需导入2 libs -->
		<!-- 
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch> <onMismatch>DENY</onMismatch> 
		</filter>
		-->
		
		<encoder>
			<pattern>${cmpName}#-#${appName}#-#%d{yyyy-MM-dd HH:mm:ss.SSS}#-#[%thread]#-#%-5level#-#%logger{35}#-#%msg%n</pattern>
		</encoder>

		<file>zzg-springcloud-nettyrpc.log</file>
		<!-- rollingPolicy：TimeBasedRollingPolicy、FixedWindowRollingPolicy -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${appName}.%d{yyyy-MM-dd}.log</fileNamePattern>
			<!-- 归档文件的最大数量 保存2个月 -->
			<maxHistory>2</maxHistory>
		</rollingPolicy>

		<!-- 合适触发文件滚动切割 -->
		<!-- <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"> 
			<maxFileSize>200MB</maxFileSize> </triggeringPolicy> -->
	</appender>

	<!-- kafka appender -->

	<!-- <appender name="KAFKA"
		class="com.github.danielwegener.logback.kafka.KafkaAppender">
		<encoder
			class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
			<layout class="ch.qos.logback.classic.PatternLayout">
				<pattern>${cmpName}#-#${appName}#-#%d{yyyy-MM-dd HH:mm:ss.SSS}#-#[%thread]#-#%-5level#-#%logger{35}#-#%msg%n</pattern>
			</layout>
		</encoder>
		<topic>log-monitor</topic>
		<keyingStrategy
			class="com.github.danielwegener.logback.kafka.keying.RoundRobinKeyingStrategy" />
		<deliveryStrategy
			class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
		<springProfile name="test,dev">
 			<producerConfig>bootstrap.servers=10.40.10.205:9092,10.40.10.206:9092,10.40.10.207:9092</producerConfig>
 		</springProfile>
		<springProfile name="prod">
			<producerConfig>bootstrap.servers=hostname1:9092,hostname2:9092,hostname3:9092</producerConfig>
		</springProfile>
	</appender> -->



	<!-- 异步处理 -->
	<!-- <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
		<appender-ref ref="KAFKA" />
	</appender> -->

	<!-- 打印com.lixin包下的info信息，并且不向上级logger传递 -->

	
	<logger name="com.springboot" level="INFO" additivity="true">
		<!-- <appender-ref ref="ASYNC" /> -->
		<appender-ref ref="FILE" />
	</logger>
	
	<!-- 根logger -->
	<logger name="org.apache.zookeeper" level="INFO" additivity="false">
	</logger>
	<logger name="com.mysql.jdbc.JDBC4Connection" level="DEBUG" additivity="false">
	</logger>
	<logger name="org.springframework.jdbc.datasource.DataSourceUtils" level="DEBUG" additivity="false">
	</logger>
	<logger name="org.mybatis.spring.transaction.SpringManagedTransaction" level="DEBUG" additivity="false">
	</logger>
	<logger name="org.apache.catalina.connector.RequestFacade" level="DEBUG" additivity="false">
	</logger>
	

	<root level="DEBUG">
		<appender-ref ref="STDOUT" />
	</root>
</configuration>
